<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mysql 36条军规]]></title>
    <url>%2F2018%2F01%2F02%2Fmysql%2Fmysql-36%E6%9D%A1%E5%86%9B%E8%A7%84%2F</url>
    <content type="text"><![CDATA[36条军规核心军规 不在数据库做运算,尽可能简单应用mysql,复杂运算移到程序段 举例： 12md5();Order by Rand(); 控制单表数据量 1231. int型不超过1000w，含char则不超过500w2. 合理分表不超载，常用分表策略：UserID、DATE、AREA...3. 限制单库表数量在300以内； 控制列数量 1表字段数少而精：io高效、全表遍历、表修复快、提高并发、alter table快 拒绝3B：拒绝大SQL，复杂事务，大批量任务 平衡范式与冗余 字段类军规 用好数值字段类型 tinyint(1Byte)、smallint(2Byte)、mediumint(3Byte)、int(4Byte)、bigint(8Byte) 123456789举例：bad caseint(1)/int(11)，填充的是0的个数举例：时间格式中timestamp、datetime、int的选择1. int: 4字节、索引快、between、范围广，适合需要进行大量时间范围查询的数据表2. datetime: 8字节、时区无关、索引最慢，范围较Timestamp广3. timestamp：4字节、时区相关[UTC存储]，范围到2037年，索引较datetime快，可自动更新，跨国应用不合适``` + 字符转化为数字 举例： 用无符号INT存储IP，而非CHAR(15):数字型VS字符串,更高效、查询更快、占用空间更小123456+ 避免使用NULL字段,特别是索引列首先，我们要搞清楚“空值” 和 “NULL” 的概念：1、空值是不占用空间的2、MySQL中的NULL其实是占用空间的&gt; 所谓的NULL就是什么都没有，连\0都没有，\0在字符串中是结束符，但是在物理内存是占空间的，等于一个字节，而NULL就是连这一个字节都没有。在数据库里是严格区分的，任何数跟NULL进行运算都是NULL, 判断值是否等于NULL，不能简单用=，而要用IS NULL关键字。 null字段很难进行查询优化: where子句中使用is null或is not null的语句优化器是不允许使用索引的 Null 列需要更多的存储空间：需要一个额外字节作为判断是否为 NULL 的标志位 Null字段的复合索引无效,索引不会包含有NULL值的列 只要列中包含有NULL值都将不会被包含在索引中，结果集中也不会包含这些记录 NOT IN子查询在有NULL值的情况下返回永远为空结果，查询容易出错 1234567891011+ 少用并拆分TEXT/BLOB，尽量不使用TEXT/BLOB,若必须则尽可能拆分到单独的表中``` 1. TEXT类型处理性能远低于VARCHAR（各自处理过程） 2. 强制生成硬盘临时表 3. 浪费更多空间 VARCHAR(65535) == 64K (UFT8)``` + 不在数据库中存图片## 索引类军规+ 谨慎合理的添加索引:改善查询，减慢更新 结合核心sql优先考虑覆盖索引 字段区分度要大，综合评估数据密度和数据分布 最好不超过字段数20% 索引并不是越多越好，能不加的索引尽量不加 1+ 自增列或者全局id做INNODB主键 主键建立聚簇索引； 主键不应该被修改,按自增顺序插入值,二级索引存储主键值 字符串不应该做主键 如果不指定主键，innodb会使用唯一且非空值索引代替； 12345+ 尽量不使用外键,可“到达”其他表，意味着锁表高并发容易死锁，由程序保证约束+ 不在索引列进行数据运算 和函数运算：会无法使用索引导致全表扫描## 约定类军规：+ 隔离线上线下: 构建数据库的生态环境,开发无线上库操作权限 原则：线上连线上，线下连线下 实时数据用real库，测试用qa库，模拟环境用sim库，开发用dev 1+ 禁止未经DBA确认的子查询 mysql子查询： 大部分情况优化较差，特别是 where中使用 in id的子查询 一般可用join改写，mysql对子查询会处理为临时表，所以一般join效率比做子查询高1+ 永远不再程序端显示加锁 外部锁对数据库不可控 高并发时是灾难 极难调试和排查 12345678+ 字符集,统一字符集：utf8;校对规则：utf8_general_ci+ 注意避免用保留字命名,eg. type+ 统一命名规范：表名、字段释义、表注释 + mysql大批量操作最好改变为手动提交+ 批量操作，避开高峰区，挪至凌晨## sql类军规+ sql语句尽可能简单 大sql缺点： 可能一条大sql就把整个库hang死 一条sql只能在一个cpu运算 5000+qps的高并发中，1s大sql意味着服务要挂 做法： 拒绝大sql，拆解成多条简单sql 用上多cpu 简单sql缓存命中率更高 减少锁表时间 拆分也要适量 1+ 保持事务连接短小 事务/连接使用原则：即开即用，用完即关 与事务无关的操作放在事务外面，减少锁资源占用 在不破坏一致性前提下，使用多个短事务代替长事务 1+ 尽可能避免使用SP/TRIG/FUNC 尽可能少用存储过程 尽量减少使用触发器 减少使用MYSQL函数对结果进行处理,由客户端程序负责1+ 尽量不要select *，只取需要的列 更少的io 可能利用覆盖索引取值 更多消耗cpu、内存、io、网络带宽 1+ OR改写为IN() or效率 o(n)，in效率 o(log n)，当n很大时，or会很慢 注意控制in的个数，建议小于200个。 eg： 大客户系统的慢sql1+ OR改写为UNION OR也可以使用到联合索引 但mysql对于or很多时候并不会优化为两次索引或者合并索引，所以or最好写做两条sql 做union all 瞎举个例子，看下union写法，其实也走合并索引：select id from t1 where name = ‘婷宝’ or ucid = ‘131’;=&gt;select id from t1 where name = ‘婷宝’unionselect id from t1 where ucid = ‘131’;123456+ 避免负向查询和%前缀模糊查询:使用不了索引,导致全表扫描 &gt; not, !=, &lt;&gt;, !&gt; , !&lt;, &quot;not exists&quot;, &quot;not in&quot;, &quot;not like&quot;+ 慎用count(*) 举例：count(col) = count(1) = count(0) = count(100) != count(col)1+ limit高效分页,limit越大，效率越低 偏移量越大则越慢 当是id时，降偏移量移到 where条件中 eg.select id from t limit 10000, 10; =&gt;select id from t where id &gt; 10000 limit 10;1+ 少用连接join 减少硬盘临时表生成，特别是有TEXT/BLOB时 mysql在join中对“order by”， “group by”优化较弱 join中的排序分组几乎都会使用fille sort 和临时表 1234+ 若无需对结果去重，用union all，而非union，union有去重开销+ group by无排序要求时使用自动排序 + 同数据类型的列值比较+ 使用load data导数据 批量数据块导入,load data比insert快约20倍 成批装载比单行装载更快，不需要每次刷新缓存 无索引时装载比索引装载更快 insert values，values，values 减少索引刷新 尽量不用insert … select, 会延迟、同步出错1+ 打散批量更新 大批量更新凌晨操作，避开高峰 凌晨不限制，白天上限默认为100条/秒 123456789+ know every sql # 优化建议## 1.批量插入代替循环单条插入## 2.当只要一行数据时使用 LIMIT 1当你查询表的有些时候，你已经知道结果只会有一条结果，在这种情况下，加上 LIMIT 1 ，MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查下一条符合记录的数据。## 3.在Join表的时候使用相当类型的例，并将其索引如果你的应用程序有很多 JOIN 查询，你应该确认两个表中Join的字段是被建过索引的。这样，MySQL内部会启动为你优化Join的SQL语句的机制。而且，这些被用来Join的字段，应该是相同的类型的。 DECIMAL和INT字段Join在一起，MySQL就无法使用它们的索引 对于那些STRING类型，还需要有相同的字符集才行。12345678## 4.千万不要 ORDER BY RAND()MySQL会不得不去执行RAND()函数（很耗CPU时间），而且这是为了每一行记录去记行，然后再对其排序。就算是用了Limit 1也无济于事（因为要排序）## 5.Prepared Statements&gt; Prepared Statements 可以检查一些你绑定好的变量，这样可以保护你的程序不会受到“SQL注入式”攻击。## 6.垂直分割&gt; “垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的 eg.大客户系统的客户属性拆解：主属性+附加属性123## 7.拆分大的 DELETE 或 INSERT 语句首先，我们的服务器并不会有太多的子进程，线程和数据库链接，因为这是极大的占服务器资源的事情，尤其是内存；其次，DELETE 或 INSERT是会锁表的，表一锁住了，别的操作都进不了；结果，如果表锁上一段时间，比如30秒钟，那么对于一个有很高访问量的站点来说，这30秒所积累的访问进程/线程，数据库链接，打开的文件数，可能不仅仅会让WEB服务Crash，还可能会让整台服务器马上挂掉；所以，需要对一个大的处理，进行拆分， eg. 使用limit + sleep while (1) { //每次只做1000条 mysql_query(“DELETE FROM logs WHERE log_date &lt;= ‘2017-11-01’ LIMIT 1000”); if (mysql_affected_rows() == 0) { break; } // 每次都要休息一会儿 usleep(50000);}``` 8. 越小的列会越快对于大多数的数据库引擎来说，硬盘操作可能是最重大的瓶颈。所以，把你的数据变得紧凑会对这种情况非常有帮助，因为这减少了对硬盘的访问。 9.小心“永久链接”“永久链接”的目的是用来减少重新创建MySQL链接的次数,在理论上来说，这听起来非常的不错。但是从个人经验（也是大多数人的）上来说，这个功能制造出来的麻烦事更多。因为，你只有有限的链接数，内存问题，文件句柄数等等。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git拉取远程分支到本地]]></title>
    <url>%2F2017%2F11%2F28%2F%E6%9D%82%E8%B0%88%2Fgit%E6%8B%89%E5%8F%96%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF%E5%88%B0%E6%9C%AC%E5%9C%B0%2F</url>
    <content type="text"><![CDATA[新建本地分支 1git checkout -b localName pull远程代码 1git pull origin remoteName fetch 1git fetch origin branchname:branchname 获取远程分支remoteName 到本地新分支localName，并跳到localName分支 1git checkout origin/remoteName -b localName]]></content>
      <categories>
        <category>版本管理</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 403 Forbidden]]></title>
    <url>%2F2017%2F11%2F27%2F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2Fnginx-403-Forbidden%2F</url>
    <content type="text"><![CDATA[nginx 403 Forbidden]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lnmp访问速度变慢排查方法]]></title>
    <url>%2F2017%2F11%2F27%2F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2Flnmp%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6%E5%8F%98%E6%85%A2%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[lnmp访问速度变慢排查方法]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志]]></title>
    <url>%2F2017%2F11%2F27%2F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2Fnginx%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[nginx 日志主要有两条指令： log_format：用来设置日志格式； access_log：用来指定日志文件的存放路径、格式（把定义的log_format 跟在后面）和缓存大小；如果不想启用日志则access_log off ; log_format 日志格式语法格式：该指令用来设置日志记录的格式。 12log_format name format [format ...] name : 给定义的格式起的名称，应该是全局唯一的 默认日志格式默认情况下，nginx的默认日志格式如下(不同版本可能略有不同)： 123log_format combined &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $body_bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot;&apos;; 日志格式举例： 1192.168.161.1 - - [25/Oct/2016:05:39:45 +0800] &quot;GET /favicon.ico HTTP/1.1&quot; 404 571 &quot;http://192.168.161.126/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36&quot; 常见内置变量 日志分类access_log该指令用来指定访问日志的路径及格式等信息。 语法格式1access_log path [log_format_name [buffer=buffer_size | off]] 示例： 1234log_format reverseRealIpFormat1 &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $body_bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot;&apos;;access_log /var/log/nginx/my-access.log reverseRealIpFormat1 buffer=8k; 在access_log中可以使用变量，但是不能与buffer同时启用,否则buffer不能启用 121. access_log /var/log/nginx/$server_name.log reverseRealIpFormat1;2. access_log /var/log/nginx/$server_name.log reverseRealIpFormat1 buffer=8k; error_logerror_log是设置记录错误日志的指令。 该指令在 http, stream, server 和 location 段都可以被指定，可以覆盖更外面的段的设置。 1error_log /var/log/nginx/error.log warn; open_log_file_cache每次记录日志都是将日志文件打开-&gt;写入-&gt;关闭,太消耗IO. open_log_file_cache 可以设置路径中含有变量的日志配置中日志文件的文件描述符缓存。 12345678open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time] | off;参数注释如下：max:设置缓存中的最大文件描述符数量，如果缓存被占满，采用LRU算法将描述符关闭。inactive:设置存活时间，默认是10smin_uses:设置在inactive时间段内，日志文件最少使用多少次后，该日志文件描述符记入缓存中，默认是1次valid:设置检查频率，默认60s 例如: 1open_log_file_cache max=655350 inactive=20s; 设置刷盘策略buffer 满 32k 才刷盘；假如 buffer 不满 5s 钟强制刷盘 1access_log /data/logs/nginx-access.log buffer=32k flush=5s; 使用举例一般log_format在全局设置，可以设置多个。access_log 可以在全局设置，但往往是定义在虚拟主机（server）中的location中 123456789101112131415161718192021http &#123; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;&quot;$status&quot; $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &apos; &apos;&quot;$gzip_ratio&quot; $request_time $bytes_sent $request_length&apos;; log_format srcache_log &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;&quot;$status&quot; $body_bytes_sent $request_time $bytes_sent $request_length &apos; &apos;[$upstream_response_time] [$srcache_fetch_status] [$srcache_store_status] [$srcache_expire]&apos;; open_log_file_cache max=1000 inactive=60s; server &#123; server_name ~^(www\.)?(.+)$; access_log logs/$2-access.log main; error_log logs/$2-error.log; location /srcache &#123; access_log logs/access-srcache.log srcache_log; &#125; &#125;&#125; 日志分析：通过对日志格式的定义，就可以使用常见的 Linux 命令行工具进行分析了： 查找访问频率最高的 URL 和次数：1cat access.log | awk -F ‘^A’ ‘&#123;print $10&#125;’ | sort | uniq -c 查找当前日志文件 500 错误的访问：1cat access.log | awk -F ‘^A’ ‘&#123;if($5 == 500) print $0&#125;’ 查找当前日志文件 500 错误的数量：1cat access.log | awk -F ‘^A’ ‘&#123;if($5 == 500) print $0&#125;’ | wc -l 查找某一分钟内 500 错误访问的数量:1cat access.log | awk -F ‘^A’ ‘&#123;if($5 == 500) print $0&#125;’ | grep ’09:00’ | wc-l 查找耗时超过 1s 的慢请求：1tail -f access.log | awk -F ‘^A’ ‘&#123;if($6&gt;1) print $0&#125;’ 假如只想查看某些位： 1tail -f access.log | awk -F ‘^A’ ‘&#123;if($6&gt;1) print $3″|”$4&#125;’ 查找 502 错误最多的 URL：1cat access.log | awk -F ‘^A’ ‘&#123;if($5==502) print $11&#125;’ | sort | uniq -c 查找 200 空白页1cat access.log | awk -F ‘^A’ ‘&#123;if($5==200 &amp;&amp; $8 &lt; 100) print $3″|”$4″|”$11″|”$6&#125;’ 切割日志Nginx 的日志都是写在一个文件当中的，不会自动地进行切割，如果访问量很大的话，将导致日志文件容量非常大，不便于管理和造成Nginx 日志写入效率低下等问题。所以，往往需要要对access_log、error_log日志进行切割。 切割日志一般利用USR1信号让nginx产生新的日志。实例： 12345678910111213141516#!/bin/bashlogdir=&quot;/data/logs/nginx&quot;pid=`cat $logdir/nginx.pid`DATE=`date -d &quot;1 hours ago&quot; +%Y%m%d%H`DATE_OLD=`date -d &quot;7 days ago&quot; +%Y%m%d`for i in `ls $logdir/*access.log`; do mv $i $i.$DATEdonefor i in `ls $logdir/*error.log`; do mv $i $i.$DATEdonekill -s USR1 $pidrm -v $logdir&quot;/access.log.&quot;$DATE_OLD*rm -v $logdir&quot;/error.log.&quot;$DATE_OLD* 1、分析： 将上面的脚本放到crontab中，每小时执行一次（0 ），这样每小时会把当前日志重命名成一个新文件；然后发送USR1这个信号让Nginx 重新生成一个新的日志。（相当于备份日志）将前7天的日志删除；2、说明：在没有执行kill -USR1 $pid之前，即便已经对文件执行了mv命令而改变了文件名称，nginx还是会向新命名的文件”*access.log.2016032623”照常写入日志数据的。原因在于：linux系统中，内核是根据文件描述符来找文件的。 3、logrotates：使用系统自带的logrotates，也可以实现nginx的日志分割，查看其bash源码，发现也是发送USR1这个信号。 使用日志排查问题举例磁盘满问题描述某周日晚8点多，收到报警短信，我们一个pv统计服务的打点统计结果突然大幅减少。赶紧登VPN上内网，发现pv统计曲线，在故障发生后，对比上周日下降到1/3左右。 解决步骤 检查了统计计算程序，未发现异常。 检查了一下机器列表发现有一台电信的机器（ds1）挂了，lvs上已经自动下线；另一台电信机器（ds2）CPU空闲率从81%下降到42% 先将这些程序 kill掉，并在 联通机房的 ls2 机器上启动起来操作完毕后，ds2的CPU空闲率回升到70%多，但pv统计结果依然维持在1/3左右 查看ds2上的打点日志(nginx的access log)，发现竟然没有新日志写入。再查看nginx的错误日志，有如下字样： 1[alert] 19963#0: *17264042335 write() to &quot;/usr/local/nginx/logs/xxx.log&quot; failed (28: No space left on device) while logging request 再用df -lh命令查看,发现磁盘已满 123Filesystem Size Used Avail Use% Mounted on/dev/xvde1 493G 493G 0G 100% /tmpfs 2.0G 0 2.0G 0% /dev/shm 清理一部分无用日志，重启nginx，再观察，统计结果终于回升了。 问题原因原来电信机房的ds1机器挂了之后，所有电信的流量都到ds2这一台机器上了，导致打点日志增长过快，加上之前有部分无用日志未及时清理，导致硬盘满了，所有电信网络打点请求的日志都没有记录下来。我们电信的请求量大约是联通的两倍，因此反映到统计结果上是下降到1/3。 结论这次问题的出现到解决，实际上经历了较长的时间。回过头来思考，其实问题是可以很快定位解决的。观察到日志下降到1/3的现象，就可以怀疑是整个电信的日志没有收集到，查一下电信机器上的打点日志 和 error log，很快可以看到问题。另外，出现程序执行不对劲，日志写入不了等等奇怪问题，都可以看看是否磁盘满了。 参考博客: http://www.jianshu.com/p/4fcaac8f2996 https://lanjingling.github.io/2016/03/14/nginx-access-log/ http://tabalt.net/blog/a-nginx-log-problem-investigation-record/]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 504错误总结]]></title>
    <url>%2F2017%2F11%2F27%2F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2FNginx%20504%E9%94%99%E8%AF%AF%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[很多人都都可能遇到过 504 Gateway Time-out。有时候会让人一头雾水。解决方法：1.通过百度可以很多人的说法，调整 nginx配置或者PHP-fpm配置，配置大家都可以百度，在这边就不多说。但是很多都尝试了没有什么软用。2.尝试过上面的方法还是回到本质上是不是整站都是504.如果不是，我建议你打开php-fpm 慢日志来查看对应的页面请求与响应慢是由哪个方法或者操作造成的。php-fpm 慢日志的配置如下：request_slowlog_timeout = 5 //5秒以上的 当一个请求该设置的超时时间后，就会将对应的PHP调用堆栈信息完整写入到慢日志中 设置为 ‘0’ 表示 ‘Off’slowlog = /var/log/php-fpm.slow.log //日志目录 再打开日志方法查看是哪个方法或者操作导致的。直接修改代码。php-fpm 慢日志 不建议在生产环境下使用 https://my.oschina.net/u/3503791/blog/908623]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 500错误总结]]></title>
    <url>%2F2017%2F11%2F27%2F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2FNginx%20500%E9%94%99%E8%AF%AF%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[500（服务器内部错误） 服务器遇到错误，无法完成请求。501（尚未实施） 服务器不具备完成请求的功能。例如，当服务器无法识别请求方法时，服务器可能会返回此代码。502（错误网关） 服务器作为网关或代理，从上游服务器收到了无效的响应。503（服务不可用） 目前无法使用服务器（由于超载或进行停机维护）。通常，这只是一种暂时的状态。504（网关超时） 服务器作为网关或代理，未及时从上游服务器接收请求。505（HTTP 版本不受支持） 服务器不支持请求中所使用的 HTTP 协议版本。 Nginx 500错误（Internal Server Error 内部服务器错误）：500错误指的是服务器内部错误，也就是服务器遇到意外情况，而无法履行请求。 500错误一般有几种情况： web脚本错误，如php语法错误，lua语法错误等。 访问量大的时候，由于系统资源限制，而不能打开过多的文件 一般分析思路： （1）查看nginx error log ，查看php error log （2）如果是too many open files，修改nginx的worker_rlimit_nofile参数，使用ulimit查看系统打开文件限制，修改/etc/security/limits.conf （3）如果是脚本的问题，则需要修复脚本错误，并优化代码 （4）各种优化都做好，还是出现too many open files，那就要考虑做负载均衡，把流量分散到不同服务器上去了。 错误原因总结： 1、硬盘空间满了 使用 df -k 查看硬盘空间是否满了。清理硬盘空间就可以解决500错误。nginx如果开启了access log，在不需要的情况下，最好关闭access log。access log会占用大量硬盘空间。 2、nginx配置文件错误 这里不是指语法错误，nginx如果配置文件有语法错误，启动的时候就会提示。当配置rewrite的时候，有些规则处理不当会出现500错误，请仔细检查自己的rewrite规则。如果配置文件里有些变量设置不当，也会出现500错误，比如引用了一个没有值的变量。 3、如果上面的问题都不存在可能是模拟的并发数太多了，需要调整一下nginx.conf的并发设置数 解决方法是： 1 打开/etc/security/limits.conf文件，加上两句 复制代码代码如下: soft nofile 65535 hard nofile 65535 2 打开/etc/nginx/nginx.conf在worker_processes的下面增加一行 复制代码代码如下:worker_rlimit_nofile 65535; 3 重新启动nginx，重新载入设置 复制代码代码如下:kill -9 ps -ef | grep php | grep -v grep | awk &#39;{print $2}&#39;/usr/bin/spawn-fcgi -a 127.0.0.1 -p 9000 -C 100 -u www-data -f /usr/bin/php-cgikillall -HUP nginx重启后再看nginx的错误日志，也没有发现500报错的情况了。 4、有可能是数据库问题我的在nginx日志php日志都没有发现什么问题, 最后发现数据库访问不了,修正后问题解决。 参考： http://www.cnblogs.com/huqiang/p/5333975.html]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP慢日志slow_log]]></title>
    <url>%2F2017%2F11%2F27%2F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2FPHP%E6%85%A2%E6%97%A5%E5%BF%97slow-log%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp; php-fpm慢日志slowl_og设置可以让开发者很好的查找哪些php进程速度过慢而导致的网站问题，让开发者方便的找到问题的所在。该方法同样适用于排查nginx的500、502问题根源，当nginx收到如上错误码时，可以确定后端php-fpm解析php出了某种问题，比如，执行错误，执行超时等。 参数设置php-fpm.conf的配置文件中有一个参数request_slowlog_timeout是这样描述的： ; The timeout for serving a single request after which a PHP backtrace will be dumped to the ‘slowlog’ file. A value of ‘0s’ means ‘off’.; Available units: s(econds)(default), m(inutes), h(ours), or d(ays); Default Value: 0; request_slowlog_timeout = 0 121. 当request_slowlog_timeout设为一个具体秒时,比如request_slowlog_timeout =5，表示如果哪个脚本执行时间大于5秒，会记录这个脚本到慢日志文件中。2. request_slowlog_timeout =0表示关闭慢日志输出 日志位置设置慢日志文件位置默认在php的安装目录下的log文件夹中，可以通过修改slowlog = log/$pool.log.slow参数来指定,如下，慢日志会记录下进程号，脚本名称，具体哪个文件哪行代码的哪个函数执行时间过长： 1234[21-Nov-2013 14:30:38] [pool www] pid 11877script_filename = /usr/local/nginx/html/www.quancha.cn/www/fyzb.php[0xb70fb88c] file_get_contents() /usr/local/nginx/html/www.quancha.cn/www/fyzb.php:2[21-Nov-2013 14:15:23] ERROR: [pool www] &apos;slowlog&apos; must be specified for use with &apos;request_slowlog_timeout&apos; request_slowlog_timeout 和 slowlog 需要同时设置 需要手动创建slowlog文件夹 日志说明开启后，如果有脚本执行超过指定的时间，就会在指定的日志文件中写入类似如下的信息： 1234[19-Dec-2013 16:54:49] [pool www] pid 18575script_filename = /home/web/htdocs/sandbox_canglong/test/tt.php[0x0000000003a00dc8] curl_exec() /home/web/htdocs/sandbox_canglong/test/tt.php:2[0x0000000003a00cd0] exfilter_curl_get() /home/web/htdocs/sandbox_canglong/test/tt.php:6 日志说明： script_filename 是入口文件 curl_exec() ： 说明是执行这个方法的时候超过执行时间的。 exfilter_curl_get() ：说明调用curl_exec()的方法 exfilter_curl_get() 。 每行冒号后面的数字是行号 开启后，在错误日志文件中也有相关记录。如下 1234[19-Dec-2013 15:55:37] WARNING: [pool www] child 18575, script &apos;/home/web/htdocs/sandbox_canglong/test/tt.php&apos; (request: &quot;GET /test/tt.php&quot;) executing too slow (1.006222 sec), logging[19-Dec-2013 15:55:37] NOTICE: child 18575 stopped for tracing[19-Dec-2013 15:55:37] NOTICE: about to trace 18575[19-Dec-2013 15:55:37] NOTICE: finished trace of 18575 使用举例问题一描述：在一次nginx应用更新的灰度过程中，我们选取一台nginx上线，观察接下来的半小时内，nginx占用内存不断增大，直到耗尽系统资源。 问题一排查步骤： 排查error_log中并没有错误信息； 监控发现新上线的nginx流量大增； 分析access_log发现新上线的nginx的QPS是原机器的6~8倍。 证实是Keepalived导致流量负载不均衡。LVS作为负载均衡时，后端的nignx配置的keepalive_timeout时间有差异导致。 LVS的负载均衡是TCP层的，只能做连接的均衡，如果Keepalive时间设置的超长，会导致路由到这个连接的请求越多 问题二描述：nginx做反向代理，有时发现某些接口较慢，通常都在3s左右。 问题二排查步骤： 配置nginx的access log记录upstream_response_time 分析发现响应大约3s多。 分析后端的access_log，处理时间都在毫秒级别。这说明问题是由于nginx跟后端connect较慢导致 参考博客： http://blog.csdn.net/leonpengweicn/article/details/42494813 http://www.bo56.com/%E5%96%84%E7%94%A8php-fpm%E7%9A%84%E6%85%A2%E6%89%A7%E8%A1%8C%E6%97%A5%E5%BF%97slow-log%EF%BC%8C%E5%88%86%E6%9E%90php%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/]]></content>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018研发校招面经]]></title>
    <url>%2F2017%2F11%2F22%2F%E6%9D%82%E8%B0%88%2F2018%E7%A0%94%E5%8F%91%E6%A0%A1%E6%8B%9B%E9%9D%A2%E7%BB%8F%2F</url>
    <content type="text"><![CDATA[工欲善其事必先利其器 阿里、腾讯 阿里面试题总结 百度、京东、蘑菇街、腾讯 阿里、华为、滴滴、百度、携程、爱奇艺、美团 百度、京东、滴滴、新浪 百度、腾讯、网易、360、去哪网 百度、头条、滴滴、阿里、搜狐 腾讯、滴滴、阿里、网易、小米、京东、美团、百度 美团、蚂蚁金服、阿里 蚂蚁金服、携程、美团、58 美团、腾讯、百度 阿里、美团、同花顺 阿里、小米、搜狗、美团、百度、腾讯、便利蜂 蚂蚁金服、链家 阿里 腾讯 小米 华为 头条、网易、美团、google、京东 腾讯、阿里 百度、阿里 蚂蚁金服、京东 知识点总结 知识点总结 知识点总结 书籍 面试书籍 高级算法 校招心路总结 校招历程 校招历程 校招历程 大数据面经，阿里，百度，头条，滴滴，美团，京东，携程 链家、58、美团、滴滴、头条、百度、腾讯 知识点]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>校招</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重启远程linux主机]]></title>
    <url>%2F2017%2F11%2F21%2Flinux%2F%E9%87%8D%E5%90%AF%E8%BF%9C%E7%A8%8Blinux%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[在终端上利用ssh，不登录远程主机，直接发送重启命令 1ssh root@192.168.8.128 &apos;reboot&apos;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP常见状态码]]></title>
    <url>%2F2017%2F11%2F20%2Fhttp%2FHTTP%E5%B8%B8%E8%A7%81%E7%8A%B6%E6%80%81%E7%A0%81%2F</url>
    <content type="text"><![CDATA[400错误 - 请求无效 (Bad request)499错误]]></content>
  </entry>
  <entry>
    <title><![CDATA[HTTP状态码出现499错误]]></title>
    <url>%2F2017%2F11%2F20%2Fhttp%2FHTTP%E7%8A%B6%E6%80%81%E7%A0%81%E5%87%BA%E7%8E%B0499%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用七牛云做hexo图床]]></title>
    <url>%2F2017%2F11%2F20%2F%E6%9D%82%E8%B0%88%2F%E4%BD%BF%E7%94%A8%E4%B8%83%E7%89%9B%E4%BA%91%E5%81%9Ahexo%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[使用七牛云存储做图床，为hexo存储引用图片]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web常见问题排查]]></title>
    <url>%2F2017%2F11%2F20%2F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一般排查方法 检查error_log 检查access_log 检查slow_log linux命令工具 tcpdump分析网络状况 程序的gdb调试 error_logerror_log提供了有关异常的丰富信: 网络超时：connect,write,read timeout File not found HTTP状态码 &nbsp;&nbsp;&nbsp;&nbsp; 举例来讲，更新nginx后，http请求不能返回完整数据，返回部分数据后请求就结束了，每次都能复现。这时候查看error_log,看到有Permission denied错误，即查实为nginx的临时写目录没有权限所造成。 slow_log&nbsp;&nbsp;&nbsp;&nbsp;php-fpm慢日志slowl_og设置可以让开发者很好的查找哪些php进程速度过慢而导致的网站问题，让开发者方便的找到问题的所在。该方法同样适用于排查nginx的500、502问题根源，当nginx收到如上错误码时，可以确定后端php-fpm解析php出了某种问题，比如，执行错误，执行超时等。 access_log对access_log进行统计分析，可以很好地展示与监控web服务的状态。包括200请求次数的变化，流量大小，后端响应时间等 1231. 统计HTTP状态码的比例，可以知道nginx服务健康状况；2. 统计响应时间，判断超时请求。3. 统计QPS，对比负载是否均衡。 linux工具命令strace 跟踪进程中的系统调用使用strace命令工具可跟踪系统调用并打印出丰富的信息，如系统调用发生的时间，调用耗时，传送的参数，调用返回结果等等。 12345常用参数有：-tt 打印系统调用发生的时间-T 打印系统调用耗时-e &lt;name&gt; 跟踪特定系统调用，比如-e open,read,write,close来追踪文件相关调用-s &lt;size&gt; 指定打印的最大长度 strace只能追踪系统调用，普通函数是无法追踪的。CPU很高，说明程序一直在跑，但strace没有异常，说明是用户状代码在消耗CPU。问题必定出现在自己程序逻辑上。 tcpdumptcpdump是linux本身得供的一款强大的网络抓包工具。对于两台设备之间传输的数据是否正常，为何响应慢等网络问题，都可以使用tcpdump来抓包排查。windows下面有一款具有同样功能的工具软件–wireshark,也很好用。 还记得刚才示例中提到的慢连接吧，Nginx的access_log显示请求响应时间为3s多，而后端是毫秒计，这种慢就可以使用tcpdump来抓包查看了 可以看到后端响应ack花了3s.这种慢连接，我们线上会经常碰到。通常nginx做反向代量连接后端时、php程序在访问后端资源时、以及php用curl请求其他接口时，经常出现慢连接的情况。这些慢连接产生的根本原因在于：–服务端listen时，设置的backlog太小，导致连接队列很小；–连接队列满时，对于新的连接请求，服务端会直接丢弃SYN包；–SYN包初始重传时间为3s； 再举一下综合案例：PHP升级后，开始运行正常，但几天后，系统负载突然上升，达到200-400左右，CPU使用不高，内存使用不高，netstat发现大量的PHP进程处于CLOSE_WAIT状态。排查：error_log与access_log都没有问题；nginx与PHP不在同一台机器，暂时无法查看其error_log；CPU、内存都不高，为何负载这么高？CLOSE_WAIT是怎么造成的 我们先从CLOSE_WAIT入手，TCP关闭连接过程中，被动关闭的一方，在接收到对方的FIN后，发送自己的FIN前，这个状态就是CLOSE_WAIT。系统调用close，关闭连接，发送FIN 从CLOSE_WAIT的状态看，PHP应该是没有调用close函数，程序可能因为某种原因堵塞，而无法调用close。启用strace追踪PHP进程到底堵塞在哪里。strace追踪结果来看，PHP进程没有堵塞，但write函数调用失败，Broken pipe说明连接已经关闭，调用close了。 继续strace分析，连接为什么关闭，是后端PHP处理太慢导致nginx超时么？从strace看到，PHP从accept到close，总共耗时1ms，nginx不可能超时。 我们启动tcpdump抓包（windows下使用wireshark查看） 发现3个异常：–3次握手nginx发送的SYN，PHP响应是ACK，而不是SYN+ACK–Nginx发送FIN关闭连接后，PHP没有发送FIN–第二个连接的SYN，PHP同样只返回ACK，但ACK序列号却是确认上一个连接的。 结合strace与tcpdump来看，accept调用比接收到SYN晚了2分钟 这里可以看到：SYN三次握手完成后，socket放到了连接队列里，accept从连接队列获取socket，如果队列过大，等到accept消费到这个socket，可能已经超时关闭连接。队列中关闭的连接处于CLOSE_WAIT状态。若PHP一个关闭的连接，就会出现Broken Pipe报错现象。这其实就是backlog设置过大引起。 总结一下，web问题排障很复杂，找到正确的方向很重要。学会看log与系统状态，学会使用统计数据（常用的一些awk,grep命令)，熟悉一些常用的工具。问题一定是有原因的，要找到root cause(真正的根本原因)]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小说推荐]]></title>
    <url>%2F2017%2F11%2F17%2F%E6%9D%82%E8%B0%88%2F%E5%B0%8F%E8%AF%B4%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[修仙 凡人修仙传 遮天 一仙难求 仙灵图谱 凡女仙葫 慢慢仙途 修真之上仙 仙本纯良 天下… 机甲 信不信我吃了你 机甲护翼 重生古言 九重紫 金陵春 慕南枝 庶女攻略 嫡谋 金枝 穿越古言 名门闺杀 穿越之丑夫 万事如意 新唐遗玉 知否，知否？应是红肥绿瘦 宋史 柔福帝姬 孤城闭 御天香 清朝 永和宫主 清穿日常 上古神话 曾许诺 香蜜沉沉烬如霜 三生三世十里桃花 三生三世枕上书 长相思 华胥引 游戏 微微一笑很倾城 玩个天下好胃疼 现代言情 何以笙箫默 原来你还在这里 致我们终将逝去的青春 山月不知心底事 青梅竹马 百花深处 娇术 花开锦绣 红茱记 热血青春 择天记]]></content>
      <categories>
        <category>小说</category>
      </categories>
      <tags>
        <tag>novel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php魔术方法]]></title>
    <url>%2F2017%2F11%2F17%2Fphp%2F%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[PHP 将所有以 开头的类法保 为魔术方法。所以在定义类方法时，除了上述魔术方法，建议不要以 为前缀 一、方法简介 __construct()，类的构造函数，在同一个类中只能声明一个构造方法 php不支持重载，如需要父类的构造函数需显式调用 __destruct()，类的析构函数，析构方法允许在销毁整个类之前执行的某些操作，无参数 call()、callStatic()，方法重载，调用未定义过的(静态)方法时被调用,可以使用__call进行友善的错误处理，避免当调用不存在的方法时产生错误，意外的导致程序中止 属性重载 12345&lt;?phppublic void __set ( string $name , mixed $value )public mixed __get ( string $name )public bool __isset ( string $name )public void __unset ( string $name ) __clone()复制时调用，复制时引用复制（浅复制），结合clone关键字实现真正的复制 autoload()作用: 是当你调用不存在的类时会被动调用，不建议使用，原因:autoload()重复定义时，冲突报错，只能有一个__autoload()函数 12345678&lt;?phpfunction __autoload($class)&#123; if(file_exists($class.".php"))&#123; require_once($class.".php"); &#125; else &#123; die("文件不存在!"); &#125;&#125; 推荐使用spl_autoload_register() 1234567891011121314151617181920&lt;?phpfunction my_autoload1($class)&#123; if(file_exists("classes/".$class.".php"))&#123; require_once("classes/".$class.".php"); &#125; else &#123; die("文件不存在!"); &#125; &#125; function my_autoload2($class)&#123; if(file_exists("core/".$class.".php"))&#123; require_once("core/".$class.".php"); &#125;else&#123; die("文件不存在!"); &#125;&#125; //将加载函数注册到PHP中spl_autoload_register("my_autoload1");spl_autoload_register("my_autoload2"); __sleep()在对一个对象序列化时(调用serialize()时)会被调用。它不接收任何参数，而且应该返回一个包含所有应该被序列化的属性的数组; __wakeup()在对存储的对象反序列化时会被调用; __toString() :在我们将对象当作字符串一样使用时会被调用; __set_state:使用var_export()函数输出对象时会调用该方法 __debugInfo(): 打印调试信息时调用 __invoke() :使用调用函数的方式调一个对象时调用该函数 123456789101112131415161718&lt;?phpclass Person &#123; public $sex; public $name; public $age; public function __construct($name="", $age=25, $sex='男')&#123; $this-&gt;name = $name; $this-&gt;age = $age; $this-&gt;sex = $sex; &#125; public function __invoke() &#123; echo '这是 个对象'; &#125; &#125; $person = new Person('jack');$person(); 二、 AOP在PHP中的实现&emsp;&emsp;在传统的OOP(面向对象编程:Object-Oriented Programming)思想 ，一般把应用程序分解成若干个对象，强调高内聚，弱耦合，从而提高应用程序的模块化程度，但是在处理某些问题的时候，OOP会显得不够灵活,比如说: 1234应用程序很多业务逻辑都要在操作之初进 “权限检查”，在操作之后进行“日志记录”，如果直接把处理逻辑直接加到每个模块中，那么无疑破坏了OOP的“单一职责”原则，模块的可重用就会大大降低，这时候传统的OOP设计往往采取的策略是加如相应的代理(Proxy)层来完成系统的功能要求，但这样的处理明显使系统整体增加一个层次的划分，复杂性也随之增加，从而给人过于厚重的感觉。 &emsp;&emsp;正是为了处理这样的问题，AOP(面向切面编程:Aspect-Oriented Programming)思想应运而生，假设把应用程序想成一个立体结构的话，OOP的刃是纵向切入系统，把系统划分为很多个模块(如:用户模块，文章模块等)， AOP的刀刃是横向切分系统，提取各个模块可能都要重复操作的部分(如:权限检查，日志记录等等)。由此可见，AOP是OOP的一个有效补充。 1234就目前的PHP来说，还没有一个完整的AOP内置实现，虽然出现 RunKit，但估计很长时间内不太可能成为PHP的缺省设置。那是么是AOP在PHP可以实现吗?当然，因为我们有get()，set()，__call()等魔术方法，结合起来使用这些方法可以为我们实现某种程度的“准AOP”，之所以说是准AOP，是因为单单从实现上来看，称其为AOP有些牵强，但是从效果上来看，又部分实现 AOP的作用，虽然其实现方式并不完美，但对于一般的使用已经够了。 三、魔术变量 LINE: 文件中的当前行号。 FILE: 文件的完整路径和文件名。当在被包含文件中，则返回被包含的文件名 DIR: 文件所在的目录。如果用在被包括文件中，则返回被包括的文件所在的目录。 FUNCTION: 常量，返回该函数被定义时的名字 CLASS: 常量，返回该类被定义时的名字(区分大小写)。 METHOD:返回该方法被定义时的名字(区分大小写)。7.NAMESPACE:当前命名空间的名称(区分大小写) 四、超全局变量 $GLOBALS:储存全局作用域中的变量。 $_SERVER:获取服务器相关信息。 $_REQUEST:获取POST和GET请求的参数 $_POST:获取表单的POST请求参数 $_GET:获取表单的GET请求参数 $_FILES:获取上传文件的的变量 $_ENV:获取服务器端环境变量的数组 $_COOKIE:浏览器cookie的操作 $_SESSION:服务端session的操作 五、结语&emsp;&emsp;PHP中的”重载”与其它绝大多数面向对象语言不同。传统的”重载”是提供多个同名的类方法，但各方法的参数类型和个数不同。 PHP所提供的”重载”(overloading)是指动态地”创建”类属性和方法。 当调用当前环境下未定义或 不可见的类属性或方法时，重载方法会被调用]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos安装php7]]></title>
    <url>%2F2017%2F11%2F16%2Fphp%2FCentos7%E5%AE%89%E8%A3%85php7%2F</url>
    <content type="text"><![CDATA[#php7 yum安装 ##哈哈哈哈加载 1hello word]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>php7</tag>
      </tags>
  </entry>
</search>
